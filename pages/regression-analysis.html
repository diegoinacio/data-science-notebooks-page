<!DOCTYPE html><html><head><!-- ! google analytics --><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GNBSFM5VZ9"></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-GNBSFM5VZ9');</script><!-- /! google analytics --><!-- ! custom meta tags --><link rel="icon" type="image/svg+xml" href="../favicon.svg"><link rel="alternate icon" href="../favicon.ico"><title>Regression Analysis | Data Analytics</title><meta name="section_name" content="Data Analytics"><meta name="section_id" content="Data-Analytics"><meta name="notebook_name" content="Regression Analysis"><meta name="notebook_id" content="regression-analysis"><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="author" content="Diego Inácio"><meta property="og:url" content="https://diegoinacio.github.io/data-science-notebooks-page/pages/regression-analysis.html"><meta name="title" property="og:title" content="Regression Analysis >> Data Science Notebooks | Diego Inácio"><meta name="description" property="og:description" content="Analysis and implementation of some of the main <em>Regression</em> models."><meta name="image" property="og:image" content="https://diegoinacio.github.io/data-science-notebooks-page/images/thumb_regression-analysis.jpg"><meta property="og:image:type" content="image/jpeg"><meta property="og:type" content="article"><meta property="article:author" content="Diego Inácio"><meta property="article:section" content="Data Science Notebooks"><!-- /! custom meta tags --><!-- ! custom notebook style --><link rel="stylesheet" href="../assets/css/notebook-standard.css"><link rel="stylesheet" href="../assets/css/notebook-custom.css"><!-- /! custom notebook style --><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script><!-- Load mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"></script><!-- MathJax configuration --><script type="text/x-mathjax-config">init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();</script><!-- End of mathjax configuration --><!-- ! custom Ko-fi importer --><script type="text/javascript" src="https://storage.ko-fi.com/cdn/widget/Widget_2.js"></script><!-- /! custom Ko-fi importer --></head><body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light"><!-- ! custom navbar --><div class="notebook-navbar"></div><!-- /! custom navbar --><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h1 id="Regression-Analysis">Regression Analysis<a class="anchor-link" href="#Regression-Analysis">¶</a></h1><hr><ul><li>Author: Diego Inácio</li><li>GitHub: <a href="https://github.com/diegoinacio">github.com/diegoinacio</a></li><li>Notebook: <a href="https://github.com/diegoinacio/data-science-notebooks/blob/master/Data-Analytics/regression-analysis.ipynb">regression-analysis.ipynb</a></li></ul><hr><p>Analysis and implementation of some of the main <em>Regression</em> models.</p></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">regression_analysis__utils</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h2 id="Linear-Regression">Linear Regression<a class="anchor-link" href="#Linear-Regression">¶</a></h2><hr></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Synthetic data 1</span>
<span class="n">x</span><span class="p">,</span> <span class="n">yA</span><span class="p">,</span> <span class="n">yB</span><span class="p">,</span> <span class="n">yC</span><span class="p">,</span> <span class="n">yD</span> <span class="o">=</span> <span class="n">synthData1</span><span class="p">()</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_linear_correlation.png" alt="linear regression correlation" title="Linear Regression Correlation"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h3 id="Simple-Linear-Regression">Simple Linear Regression<a class="anchor-link" href="#Simple-Linear-Regression">¶</a></h3><hr>$$ \large y_i=mx_i+b $$<p>Where <strong>m</strong> describes the angular coefficient (or line slope) and <strong>b</strong> the linear coefficient (or line y-intersept).</p>$$ \large m=\frac{\sum_i^n (x_i-\overline{x})(y_i-\overline{y})}{\sum_i^n (x_i-\overline{x})^2} $$$$ \large b=\overline{y}-m\overline{x} $$</div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">linearRegression_simple</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">X_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">y_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">num</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">den</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">=</span> <span class="n">num</span><span class="o">/</span><span class="n">den</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="n">y_</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="o">*</span><span class="n">X_</span>
    
    <span class="k">def</span> <span class="nf">pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span>
</pre></div></div></div></div></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="n">lrs</span> <span class="o">=</span> <span class="n">linearRegression_simple</span><span class="p">()</span>
</pre></div></div></div></div></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">lrs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yA</span><span class="p">)</span>
<span class="n">yA_</span> <span class="o">=</span> <span class="n">lrs</span><span class="o">.</span><span class="n">pred</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">lrs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yB</span><span class="p">)</span>
<span class="n">yB_</span> <span class="o">=</span> <span class="n">lrs</span><span class="o">.</span><span class="n">pred</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">lrs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yC</span><span class="p">)</span>
<span class="n">yC_</span> <span class="o">=</span> <span class="n">lrs</span><span class="o">.</span><span class="n">pred</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">lrs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yD</span><span class="p">)</span>
<span class="n">yD_</span> <span class="o">=</span> <span class="n">lrs</span><span class="o">.</span><span class="n">pred</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div></div></div></div></div><div class="jp-Cell-outputWrapper"><div class="jp-OutputArea jp-Cell-outputArea"><div class="jp-OutputArea-child"><div class="jp-OutputPrompt jp-OutputArea-prompt"></div><div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain"><pre>CPU times: total: 15.6 ms
Wall time: 998 µs
</pre></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_linear_pred.png" alt="linear regression prediction" title="Linear Regression Prediction"></p>$$ \large MSE=\frac{1}{n} \sum_i^n (Y_i- \hat{Y}_i)^2 $$<p><img src="output/regression_linear_residual.png" alt="linear regression residuals" title="Linear Regression Residuals"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h3 id="Multiple-Linear-Regression">Multiple Linear Regression<a class="anchor-link" href="#Multiple-Linear-Regression">¶</a></h3><hr>$$ \large y=m_1x_1+m_2x_2+...+m_nx_n+b $$</div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">linearRegression_multiple</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">X_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">y_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">num</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">den</span> <span class="o">=</span> <span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">X_</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">=</span> <span class="n">num</span><span class="o">/</span><span class="n">den</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="n">y_</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="o">*</span><span class="n">X_</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span>
</pre></div></div></div></div></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="n">lrm</span> <span class="o">=</span> <span class="n">linearRegression_multiple</span><span class="p">()</span>
</pre></div></div></div></div></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span> 
<span class="c1"># Synthetic data 2</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">synthData2</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>

<span class="c1"># Prediction</span>
<span class="n">lrm</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_</span> <span class="o">=</span> <span class="n">lrm</span><span class="o">.</span><span class="n">pred</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span>
</pre></div></div></div></div></div><div class="jp-Cell-outputWrapper"><div class="jp-OutputArea jp-Cell-outputArea"><div class="jp-OutputArea-child"><div class="jp-OutputPrompt jp-OutputArea-prompt"></div><div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain"><pre>CPU times: total: 0 ns
Wall time: 0 ns
</pre></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_linear_multiple_pred.png" alt="linear regression multiple" title="Linear Regression Multiple"> <img src="output/regression_linear_multipla_residual.png" alt="linear regression multiple residuals" title="Linear Regression Multiple Residuals"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h3 id="Gradient-Descent">Gradient Descent<a class="anchor-link" href="#Gradient-Descent">¶</a></h3><hr>$$ \large e_{m,b}=\frac{1}{n} \sum_i^n (y_i-(mx_i+b))^2 $$<p>To perform the gradient descent as a function of the error, it is necessary to calculate the gradient vector $\nabla$ of the function, described by:</p>$$ \large \nabla e_{m,b}=\Big\langle\frac{\partial e}{\partial m},\frac{\partial e}{\partial b}\Big\rangle $$<p>where:</p>$$ \large \begin{aligned} \frac{\partial e}{\partial m}&amp;=\frac{2}{n} \sum_{i}^{n}-x_i(y_i-(mx_i+b)), \\ \frac{\partial e}{\partial b}&amp;=\frac{2}{n} \sum_{i}^{n}-(y_i-(mx_i+b)) \end{aligned} $$</div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">linearRegression_GD</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">mo</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                 <span class="n">bo</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                 <span class="n">rate</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">=</span> <span class="n">mo</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">=</span> <span class="n">bo</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rate</span> <span class="o">=</span> <span class="n">rate</span>
        
    <span class="k">def</span> <span class="nf">fit_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span>
        <span class="n">dm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">*</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="p">)))</span>
        <span class="n">db</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">n</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_m</span> <span class="o">-=</span> <span class="n">dm</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_b</span> <span class="o">-=</span> <span class="n">db</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">rate</span>
        
    <span class="k">def</span> <span class="nf">pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_m</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_b</span>
</pre></div></div></div></div></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">lrgd</span> <span class="o">=</span> <span class="n">linearRegression_GD</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Synthetic data 3</span>
<span class="n">x</span><span class="p">,</span> <span class="n">x_</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">synthData3</span><span class="p">()</span>

<span class="n">iterations</span> <span class="o">=</span> <span class="mi">3072</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
    <span class="n">lrgd</span><span class="o">.</span><span class="n">fit_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_</span> <span class="o">=</span> <span class="n">lrgd</span><span class="o">.</span><span class="n">pred</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div></div></div></div></div><div class="jp-Cell-outputWrapper"><div class="jp-OutputArea jp-Cell-outputArea"><div class="jp-OutputArea-child"><div class="jp-OutputPrompt jp-OutputArea-prompt"></div><div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain"><pre>CPU times: total: 62.5 ms
Wall time: 50.2 ms
</pre></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_linear_gradDesc.gif" alt="gradient descent" title="Gradient Descent"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h2 id="Logistic-Regression">Logistic Regression<a class="anchor-link" href="#Logistic-Regression">¶</a></h2><hr>$$ \large h_{\theta}(x)=g(\theta^Tx)=\frac{e^{\theta^Tx}}{1+e^{\theta^Tx}}=\frac{1}{1+e^{-\theta^Tx}} $$<p>where:</p>$$ \large \theta^Tx= \begin{bmatrix} \theta_0 \\ \theta_1 \\ \vdots \\ \theta_i \end{bmatrix} \begin{bmatrix} 1 &amp; x_{11} &amp; \cdots &amp; x_{1i} \\ 1 &amp; x_{21} &amp; \cdots &amp; x_{2i} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; x_{n1} &amp; \cdots &amp; x_{ni} \end{bmatrix} $$<p>where:</p><ul><li>$\large h_\theta(x)$ is the hypothesis;</li><li>$\large g(z)$ is the logistic function or <em>sigmoid</em>;</li><li>$\large \theta_i$ is the parameters (or <em>weights</em>).</li></ul></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">arraycast</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Decorator for vectors and matrices cast</span>
<span class="sd">    '''</span>
    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[]):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wrap</span>

<span class="k">class</span> <span class="nc">logisticRegression</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">1024</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rate</span> <span class="o">=</span> <span class="n">rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iters</span> <span class="o">=</span> <span class="n">iters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span>
    <span class="k">def</span> <span class="nf">_sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Z</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Z</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">_dsigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">Z</span><span class="p">))</span>
    <span class="nd">@arraycast</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_iters</span><span class="p">):</span>
            <span class="n">thetaTx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
            <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">thetaTx</span><span class="p">)</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">h</span> <span class="o">-</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span> <span class="o">-=</span> <span class="n">grad</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_rate</span>
    <span class="nd">@arraycast</span>
    <span class="k">def</span> <span class="nf">pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_theta</span><span class="o">.</span><span class="n">T</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
</pre></div></div></div></div></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[12]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Synthetic data 5</span>
<span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">synthData5</span><span class="p">()</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_logistic_data.png" alt="logistic regression data" title="Logistic Regression Data"></p></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="c1"># Training</span>
<span class="n">rlogb</span> <span class="o">=</span> <span class="n">logisticRegression</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="n">rlogb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="c1"># rlogb.pred(x1, x2)</span>
</pre></div></div></div></div></div><div class="jp-Cell-outputWrapper"><div class="jp-OutputArea jp-Cell-outputArea"><div class="jp-OutputArea-child"><div class="jp-OutputPrompt jp-OutputArea-prompt"></div><div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain"><pre>CPU times: total: 0 ns
Wall time: 14 ms
</pre></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_logistic_gradDesc.gif" alt="logistic regression training" title="Logistic Regression Training"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p>To find the boundary line components:</p>$$ \large \theta_0+\theta_1 x_1+\theta_2 x_2=0 $$<p>Considering $\large x_2$ as the dependent variable:</p>$$ \large x_2=-\frac{\theta_0+\theta_1 x_1}{\theta_2} $$</div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Prediction</span>
<span class="n">w0</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span> <span class="o">=</span> <span class="n">rlogb</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span> <span class="p">(</span><span class="n">w0</span> <span class="o">+</span> <span class="n">w1</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">w2</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_logistic_pred.png" alt="regressão logística prediction" title="Logistic Regression Prediction"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h2 id="Polynomial-Regression">Polynomial Regression<a class="anchor-link" href="#Polynomial-Regression">¶</a></h2><hr><p>Given the function:</p>$$ \large f(x)=x^3-3x^2+x+1+\epsilon $$</div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Synthetic data 6</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">synthData6</span><span class="p">()</span>

<span class="c1"># Predicting with Linear Regression</span>
<span class="n">lrs</span> <span class="o">=</span> <span class="n">linearRegression_simple</span><span class="p">()</span>
<span class="n">lrs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_polynomial_linear.png" alt="polynomial data and linear regression" title="Polynomial data and Linear Regression"></p></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><h3 id="Algorithm">Algorithm<a class="anchor-link" href="#Algorithm">¶</a></h3><hr>$$ \large \vec{y}=\mathbf{X}\vec{\mathbf{\beta}}+\vec{\epsilon} $$<p>where $\large \mathbf{X}$ (or $\large \mathbf{V}$) is the <em>Vandermonde's matrix</em> of the independent variable, parametrised by the maximum degree $\large m$, a response vector $\large \vec{y}$, a parameter vector $\large \vec{\mathbf{\beta}}$ and a random error vector $\large \vec{\epsilon}$. In the form of a system of linear equations, we have:</p>$$ \large \begin{bmatrix} y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_n \end{bmatrix} = \begin{bmatrix} 1 &amp; x_1 &amp; x_1^2 &amp;\cdots &amp; x_1^m \\ 1 &amp; x_2 &amp; x_2^2 &amp; \cdots &amp; x_2^m \\ 1 &amp; x_3 &amp; x_3^2 &amp; \cdots &amp; x_3^m \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; x_n &amp; x_n^2 &amp; \cdots &amp; x_n^m \end{bmatrix} \begin{bmatrix} \beta_1 \\ \beta_2 \\ \beta_3 \\ \vdots \\ \beta_m \end{bmatrix} + \begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\ \epsilon_3 \\ \vdots \\ \epsilon_n \end{bmatrix} $$<p>By means of the Least Squares Method, the estimated coefficient vector is given by:</p>$$ \large \widehat{\vec{\mathbf{\beta}}}=(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\vec{y} $$</div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">arraycast</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    Decorador para conversão de vetores e matrizes</span>
<span class="sd">    '''</span>
    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[]):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wrap</span>

<span class="k">class</span> <span class="nc">polynomialRegression</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">beta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span>
    <span class="nd">@arraycast</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[]):</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">X</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="n">VTV</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
        <span class="n">VTV_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">VTV</span><span class="p">)</span>
        <span class="n">Vi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">VTV_i</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Vi</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nd">@arraycast</span>
    <span class="k">def</span> <span class="nf">pred</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_beta</span><span class="p">)</span>
</pre></div></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p>Notice that our class has an attribute called <em>degree</em> which is the maximum degree of our function $\large f(x)$. In our example it should be $\large m=3$.</p></div></div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"><div class="jp-Cell-inputWrapper"><div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[17]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"><div class="CodeMirror cm-s-jupyter"><div class="highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>
<span class="n">polreg</span> <span class="o">=</span> <span class="n">polynomialRegression</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">polreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div></div></div></div></div><div class="jp-Cell-outputWrapper"><div class="jp-OutputArea jp-Cell-outputArea"><div class="jp-OutputArea-child"><div class="jp-OutputPrompt jp-OutputArea-prompt"></div><div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain"><pre>CPU times: total: 0 ns
Wall time: 8.85 ms
</pre></div></div></div></div></div><div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt"></div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"><p><img src="output/regression_polynomial_pred.png" alt="polynomial regression" title="Polynomial Regression"></p></div></div><!-- ! custom footer --><footer class="notebook-footer"></footer><!-- /! custom footer --><!-- ! custom scripts --><script src="../assets/template/notebook.js"></script><!-- /! custom scripts --></body></html>